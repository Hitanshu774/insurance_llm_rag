{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29f2dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22cfed09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.45s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "#loading the llama model by using huggingface pipelines\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "Llama = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(Llama)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    Llama,\n",
    "    dtype = torch.float16,\n",
    "    device_map = \"auto\"\n",
    ")\n",
    "\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c89e9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 76 files in the knowledge base\n",
      "Total characters in knowledge base: 304,434\n"
     ]
    }
   ],
   "source": [
    "# number of files in the document\n",
    "knowledge_base_path = \"knowledge-base/**/*.md\"\n",
    "files = glob.glob(knowledge_base_path, recursive=True)\n",
    "print(f\"Found {len(files)} files in the knowledge base\")\n",
    "\n",
    "# number of characters in all the documents\n",
    "entire_knowledge_base = \"\"\n",
    "\n",
    "for file_path in files:\n",
    "    with open(file_path, 'r', encoding=\"utf8\") as f:\n",
    "        entire_knowledge_base += f.read()\n",
    "        entire_knowledge_base += \"\\n\\n\"\n",
    "print(f\"Total characters in knowledge base: {len(entire_knowledge_base):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491e14ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens for meta-llama/Llama-3.2-3B-Instruct: 63,715\n"
     ]
    }
   ],
   "source": [
    "# number of tokens in all the documents\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(Llama)################################\n",
    "# encoding = tiktoken.encoding_for_model(Llama)\n",
    "# tokens = encoding.encode(entire_knowledge_base)\n",
    "tokens = tokenizer.encode(entire_knowledge_base)######################\n",
    "\n",
    "\n",
    "token_count = len(tokens)\n",
    "print(f\"Total tokens for {Llama}: {token_count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1adccb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 76 documents\n"
     ]
    }
   ],
   "source": [
    "# Load in everything in the knowledgebase using LangChain's loaders\n",
    "\n",
    "folders = glob.glob(\"knowledge-base/*\")\n",
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs={'encoding': 'utf-8'})\n",
    "    folder_docs = loader.load()\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f218a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'knowledge-base\\\\company\\\\careers.md', 'doc_type': 'company'}, page_content=\"# Careers at Insurellm\\n\\n## Why Join Insurellm?\\n\\nAt Insurellm, we're not just building software—we're revolutionizing an entire industry. Since our founding in 2015, we've evolved from a high-growth startup to a lean, profitable company with 32 highly talented employees managing 32 active contracts across all eight of our product lines.\\n\\nAfter reaching 200 employees in 2020, we strategically restructured in 2022-2023 to focus on sustainable growth, operational excellence, and building a world-class remote-first culture. Today, we're a tight-knit team of exceptional professionals who deliver outsized impact through automation, AI, and strategic focus on high-value enterprise clients—from regional insurers to global reinsurance partners.\\n\\n### Our Culture\\n\\nWe live by our core values every day:\\n- **Innovation First**: We encourage experimentation and creative problem-solving\\n- **Customer Obsession**: Your work directly impacts 32 active client operations spanning the entire insurance value chain\\n- **Integrity & Transparency**: We build trust through ethical behavior and open communication\\n- **Collaborative Excellence**: Diverse perspectives and teamwork drive our success\\n\\n### What We Offer\\n\\n- Competitive compensation with equity participation\\n- Comprehensive health, dental, and vision insurance\\n- Flexible working arrangements and generous PTO\\n- Professional development programs and mentorship\\n- Clear career progression paths\\n- Latest technologies and tools\\n- Inclusive, diverse work environment\\n\\n## Current Opportunities\\n\\n### Engineering\\n\\n**Senior Full Stack Engineer** - San Francisco, CA\\n- Lead development of next-generation insurance platform features\\n- Work with React, Node.js, Python, and cloud technologies\\n- Mentor junior engineers and drive technical decisions\\n- 5+ years experience required\\n\\n**Backend Software Engineer** - San Francisco, CA / Austin, TX\\n- Build scalable microservices and APIs\\n- Optimize system performance and reliability\\n- Collaborate with product and design teams\\n- 3+ years experience with Java, Python, or Go\\n\\n**Frontend Developer** - Remote\\n- Create intuitive user interfaces for our insurance platforms\\n- Work with modern frameworks (React, Vue, or Angular)\\n- Ensure accessibility and responsive design\\n- 2+ years experience required\\n\\n**DevOps Engineer** - New York, NY\\n- Manage cloud infrastructure (AWS/GCP)\\n- Implement CI/CD pipelines and automation\\n- Monitor system performance and security\\n- 3+ years experience in DevOps/SRE\\n\\n**Mobile Developer (iOS/Android)** - San Francisco, CA\\n- Build native mobile applications for our marketplace\\n- Create seamless user experiences\\n- Integrate with backend APIs\\n- 3+ years mobile development experience\\n\\n### Data & Analytics\\n\\n**Senior Data Scientist** - San Francisco, CA / New York, NY\\n- Develop predictive models for insurance risk assessment\\n- Build recommendation systems for our marketplace\\n- Lead data-driven product initiatives\\n- PhD or MS in related field preferred, 4+ years experience\\n\\n**Data Engineer** - Austin, TX\\n- Design and maintain data pipelines\\n- Build data warehousing solutions\\n- Optimize data infrastructure for scale\\n- 3+ years experience with SQL, Python, and ETL tools\\n\\n**Business Intelligence Analyst** - Chicago, IL\\n- Create dashboards and reports for stakeholders\\n- Analyze business metrics and trends\\n- Support data-driven decision making\\n- 2+ years experience with BI tools (Tableau, Looker, etc.)\\n\\n### Product & Design\\n\\n**Product Manager** - San Francisco, CA\\n- Define product roadmap and strategy\\n- Work closely with engineering and design teams\\n- Gather customer insights and market research\\n- 3+ years product management experience in B2B SaaS\\n\\n**UX/UI Designer** - Remote\\n- Design user experiences for our insurance platforms\\n- Conduct user research and usability testing\\n- Create design systems and prototypes\\n- 3+ years design experience, insurance/fintech preferred\\n\\n### Sales & Customer Success\\n\\n**Account Executive** - New York, NY / Chicago, IL / Austin, TX\\n- Manage B2B sales cycle for enterprise clients\\n- Build relationships with insurance companies\\n- Exceed revenue targets and grow territory\\n- 3+ years B2B sales experience, SaaS preferred\\n\\n**Sales Development Representative** - Austin, TX / Remote\\n- Generate qualified leads for sales team\\n- Conduct outreach to prospective clients\\n- Research and identify target accounts\\n- 1+ years SDR/BDR experience preferred\\n\\n**Customer Success Manager** - San Francisco, CA / New York, NY\\n- Ensure client satisfaction and retention\\n- Drive product adoption and expansion\\n- Serve as trusted advisor to clients\\n- 2+ years customer success experience in SaaS\\n\\n**Solutions Engineer** - Remote\\n- Provide technical expertise during sales process\\n- Conduct product demonstrations and POCs\\n- Support implementation and integration\\n- 3+ years technical pre-sales experience\\n\\n### Operations & Support\\n\\n**Technical Support Specialist** - Remote\\n- Provide tier 2/3 technical support to clients\\n- Troubleshoot platform issues\\n- Create documentation and knowledge base articles\\n- 2+ years technical support experience\\n\\n**HR Business Partner** - San Francisco, CA\\n- Partner with leadership on people strategy\\n- Support talent development and retention\\n- Drive culture and engagement initiatives\\n- 4+ years HR experience, tech industry preferred\\n\\n## How to Apply\\n\\nVisit our careers portal at careers.insurellm.com or send your resume to jobs@insurellm.com. Please include the position title in your subject line.\\n\\nInsurellm is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.\")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "826104f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divided into 413 chunks\n",
      "First chunk:\n",
      "\n",
      "page_content='# About Insurellm\n",
      "\n",
      "Insurellm was founded by Avery Lancaster in 2015 as an insurance tech startup designed to disrupt an industry in need of innovative products. Its first product was Markellm, the marketplace connecting consumers with insurance providers.\n",
      "\n",
      "The company experienced rapid growth in its first five years, expanding its product portfolio to include Carllm (auto insurance portal), Homellm (home insurance portal), and Rellm (enterprise reinsurance platform). By 2020, Insurellm had reached a peak of 200 employees with 12 offices across the US.' metadata={'source': 'knowledge-base\\\\company\\\\about.md', 'doc_type': 'company'}\n"
     ]
    }
   ],
   "source": [
    "# Divide into chunks using the RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Divided into {len(chunks)} chunks\")\n",
    "print(f\"First chunk:\\n\\n{chunks[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2585f570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'knowledge-base\\\\contracts\\\\Contract with GlobalRe Partners for Rellm.md', 'doc_type': 'contracts'}, page_content='13. **Climate Risk Analytics:** Forward-looking climate modeling:\\n    - IPCC climate scenario analysis (RCP 2.6, 4.5, 8.5)\\n    - Transition risk assessment\\n    - Physical risk modeling for perils (hurricane, wildfire, flood, drought)\\n    - Sea level rise impact analysis\\n    - Temperature trend incorporation\\n    - Climate-adjusted pricing recommendations\\n    - Stranded asset identification\\n    - Green reinsurance opportunities\\n\\n---\\n\\n## Support\\n\\nInsurellm commits to comprehensive Enterprise-level support for GlobalRe Partners:\\n\\n1. **Dedicated Success Team:**\\n   - Executive sponsor (CEO-level) with quarterly strategic reviews\\n   - Dedicated Senior Vice President of Customer Success with bi-weekly engagement\\n   - Technical Account Manager for platform optimization\\n   - Solutions Architect team (2 FTE) for strategic initiatives\\n   - Catastrophe modeling specialist for analytics support\\n   - Quarterly executive business reviews with C-suite participation from both organizations')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[100]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee602ca3",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d317ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 413 documents\n"
     ]
    }
   ],
   "source": [
    "# Pick an embedding model\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "#embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "db_name = \"vector_db\"\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e02217e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 413 vectors with 384 dimensions in the vector store\n"
     ]
    }
   ],
   "source": [
    "# Let's investigate the vectors\n",
    "\n",
    "collection = vectorstore._collection\n",
    "count = collection.count()\n",
    "\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"There are {count:,} vectors with {dimensions:,} dimensions in the vector store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d7b8af",
   "metadata": {},
   "source": [
    "### vector visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f81316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f763d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56756e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef2359a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
